{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "name": "CRISTOPHER - RedesNeurais2021-06-25-17-59.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asengardeon/rede-neural-com-pytorch/blob/main/CRISTOPHER_RedesNeurais2021_06_25_17_59.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3a9e7252"
      },
      "source": [
        "# APAGAR (links úteis)\n",
        "# https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
        "# https://towardsdatascience.com/your-first-neural-network-in-pytorch-725631ae0fc\n",
        "# https://medium.com/@nutanbhogendrasharma/build-neural-network-with-pytorch-52ee7074660"
      ],
      "id": "3a9e7252",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8a85d09"
      },
      "source": [
        "# Importando as bibliotecas\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "id": "c8a85d09",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20e8d78a"
      },
      "source": [
        "# Carregando o dataframe lithology\n",
        "df_lithology = pd.read_csv('lithology.csv', sep = ';', decimal = '.')"
      ],
      "id": "20e8d78a",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f010b504",
        "outputId": "0012c445-9b91-4bae-ea51-b126f10ad799"
      },
      "source": [
        "# Visualizando as informações do dataframe lithology\n",
        "df_lithology.info()"
      ],
      "id": "f010b504",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 39117 entries, 0 to 39116\n",
            "Data columns (total 31 columns):\n",
            " #   Column                            Non-Null Count  Dtype  \n",
            "---  ------                            --------------  -----  \n",
            " 0   DEPTH_MD                          39117 non-null  float64\n",
            " 1   X_LOC                             39117 non-null  float64\n",
            " 2   Y_LOC                             39117 non-null  float64\n",
            " 3   Z_LOC                             39117 non-null  float64\n",
            " 4   CALI                              39117 non-null  float64\n",
            " 5   RSHA                              39117 non-null  float64\n",
            " 6   RMED                              39117 non-null  float64\n",
            " 7   RDEP                              39117 non-null  float64\n",
            " 8   RHOB                              39117 non-null  float64\n",
            " 9   GR                                39117 non-null  float64\n",
            " 10  NPHI                              39117 non-null  float64\n",
            " 11  PEF                               39117 non-null  float64\n",
            " 12  DTC                               39117 non-null  float64\n",
            " 13  SP                                39117 non-null  float64\n",
            " 14  BS                                39117 non-null  float64\n",
            " 15  ROP                               39117 non-null  float64\n",
            " 16  DCAL                              39117 non-null  float64\n",
            " 17  DRHO                              39117 non-null  float64\n",
            " 18  MUDWEIGHT                         39117 non-null  float64\n",
            " 19  RMIC                              39117 non-null  float64\n",
            " 20  FORCE_2020_LITHOFACIES_LITHOLOGY  39117 non-null  float64\n",
            " 21  Carbon_Index                      39117 non-null  float64\n",
            " 22  Normalized_RHOB                   39117 non-null  float64\n",
            " 23  Normalized_GR                     39117 non-null  float64\n",
            " 24  Delta_DTC                         39117 non-null  float64\n",
            " 25  Delta_RHOB                        39117 non-null  float64\n",
            " 26  Delta_GR                          39117 non-null  float64\n",
            " 27  Delta_DEPTH_MD                    39117 non-null  float64\n",
            " 28  Delta_Carbon_Index                39117 non-null  float64\n",
            " 29  GROUP_encoded                     39116 non-null  float64\n",
            " 30  FORMATION_encoded                 39116 non-null  float64\n",
            "dtypes: float64(31)\n",
            "memory usage: 9.3 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fda42568",
        "outputId": "fc11a3a5-a16f-4fcb-f0be-6c9a96df66c9"
      },
      "source": [
        "# Verificando a correlação das variáveis em relação a variável FORCE_2020_LITHOFACIES_LITHOLOGY\n",
        "corr = df_lithology.corr(method = 'pearson')\n",
        "force_2020_lithofacies_lithology_corr = corr[['FORCE_2020_LITHOFACIES_LITHOLOGY']]\n",
        "force_2020_lithofacies_lithology_corr.FORCE_2020_LITHOFACIES_LITHOLOGY.abs().sort_values()"
      ],
      "id": "fda42568",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RSHA                                0.004514\n",
              "Delta_DEPTH_MD                      0.004955\n",
              "Delta_DTC                           0.005740\n",
              "Delta_GR                            0.014424\n",
              "DRHO                                0.015981\n",
              "RHOB                                0.022883\n",
              "Normalized_RHOB                     0.023248\n",
              "Delta_RHOB                          0.024108\n",
              "Delta_Carbon_Index                  0.024417\n",
              "MUDWEIGHT                           0.025657\n",
              "CALI                                0.031974\n",
              "Y_LOC                               0.058606\n",
              "X_LOC                               0.063437\n",
              "Carbon_Index                        0.068956\n",
              "DCAL                                0.075241\n",
              "PEF                                 0.083927\n",
              "Z_LOC                               0.126443\n",
              "DEPTH_MD                            0.126468\n",
              "Normalized_GR                       0.127538\n",
              "RDEP                                0.128699\n",
              "DTC                                 0.130576\n",
              "ROP                                 0.132193\n",
              "FORMATION_encoded                   0.136693\n",
              "RMED                                0.151731\n",
              "GROUP_encoded                       0.170218\n",
              "BS                                  0.186894\n",
              "SP                                  0.202940\n",
              "NPHI                                0.245655\n",
              "GR                                  0.303780\n",
              "FORCE_2020_LITHOFACIES_LITHOLOGY    1.000000\n",
              "RMIC                                     NaN\n",
              "Name: FORCE_2020_LITHOFACIES_LITHOLOGY, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b81f6f02"
      },
      "source": [
        "# Convertendo a coluna FORCE_2020_LITHOFACIES_LITHOLOGY para índices\n",
        "mapping = {\n",
        "    30000: 0,\n",
        "    65030: 1,\n",
        "    65000: 2,\n",
        "    80000: 3,\n",
        "    74000: 4,\n",
        "    70000: 5,\n",
        "    70032: 6,\n",
        "    88000: 7,\n",
        "    86000: 8,\n",
        "    99000: 9,\n",
        "    90000: 10,\n",
        "    93000: 11\n",
        "}\n",
        "df_lithology.FORCE_2020_LITHOFACIES_LITHOLOGY = df_lithology.FORCE_2020_LITHOFACIES_LITHOLOGY.apply(lambda x: mapping[x])"
      ],
      "id": "b81f6f02",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19bfd879"
      },
      "source": [
        "# Dividindo o dataframe lithology em Features (X) e Target (y)\n",
        "X1 = df_lithology.drop(['FORCE_2020_LITHOFACIES_LITHOLOGY', 'GROUP_encoded', 'FORMATION_encoded'], axis = 1).values\n",
        "y1 = df_lithology.FORCE_2020_LITHOFACIES_LITHOLOGY.values\n",
        "\n",
        "X2 = df_lithology.drop(['FORCE_2020_LITHOFACIES_LITHOLOGY', 'GROUP_encoded', 'FORMATION_encoded'], axis = 1).values\n",
        "y2 = df_lithology.FORCE_2020_LITHOFACIES_LITHOLOGY.values\n",
        "\n",
        "X3 = df_lithology.drop(['FORCE_2020_LITHOFACIES_LITHOLOGY', 'GROUP_encoded', 'FORMATION_encoded'], axis = 1).values\n",
        "y3 = df_lithology.FORCE_2020_LITHOFACIES_LITHOLOGY.values"
      ],
      "id": "19bfd879",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78cdb656"
      },
      "source": [
        "# Dividindo as features e o target do dataframe lithology em treino e teste\n",
        "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size = 0.1)\n",
        "X1_train = torch.FloatTensor(X1_train)\n",
        "X1_test = torch.FloatTensor(X1_test)\n",
        "y1_train = torch.LongTensor(y1_train)\n",
        "y1_test = torch.LongTensor(y1_test)\n",
        "\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size = 0.1)\n",
        "X2_train = torch.FloatTensor(X2_train)\n",
        "X2_test = torch.FloatTensor(X2_test)\n",
        "y2_train = torch.LongTensor(y2_train)\n",
        "y2_test = torch.LongTensor(y2_test)\n",
        "\n",
        "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size = 0.1)\n",
        "X3_train = torch.FloatTensor(X3_train)\n",
        "X3_test = torch.FloatTensor(X3_test)\n",
        "y3_train = torch.LongTensor(y3_train)\n",
        "y3_test = torch.LongTensor(y3_test)"
      ],
      "id": "78cdb656",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e313ad2f"
      },
      "source": [
        "# Definindo os modelos\n",
        "class FirstModel(nn.Module):\n",
        "    # Definindo quantidade de camadas (7) e quantidade de neurônios\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.l1 = nn.Linear(in_features = 28, out_features = 56)\n",
        "        self.l2 = nn.Linear(in_features = 56, out_features = 84)\n",
        "        self.l3 = nn.Linear(in_features = 84, out_features = 112)\n",
        "        self.l4 = nn.Linear(in_features = 112, out_features = 84)\n",
        "        self.l5 = nn.Linear(in_features = 84, out_features = 56)\n",
        "        self.l6 = nn.Linear(in_features = 56, out_features = 28)\n",
        "        self.output = nn.Linear(in_features = 28, out_features = 12)\n",
        "\n",
        "    # Utilizando ReLU para a função de ativação\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.l1(x))\n",
        "        x = F.relu(self.l2(x))\n",
        "        x = F.relu(self.l3(x))\n",
        "        x = F.relu(self.l4(x))\n",
        "        x = F.relu(self.l5(x))\n",
        "        x = F.relu(self.l6(x))\n",
        "        x = self.output(x)\n",
        "        return x\n",
        "\n",
        "class SecondModel(nn.Module):\n",
        "    # Definindo quantidade de camadas (5) e quantidade de neurônios\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.l1 = nn.Linear(in_features = 28, out_features = 42)\n",
        "        self.l2 = nn.Linear(in_features = 42, out_features = 70)\n",
        "        self.l3 = nn.Linear(in_features = 70, out_features = 42)\n",
        "        self.l4 = nn.Linear(in_features = 42, out_features = 28)\n",
        "        self.output = nn.Linear(in_features = 28, out_features = 12)\n",
        "\n",
        "    # Utilizando SoftMax para a função de ativação\n",
        "    def forward(self, x):\n",
        "        x = F.softmax(self.l1(x))\n",
        "        x = F.softmax(self.l2(x))\n",
        "        x = F.softmax(self.l3(x))\n",
        "        x = F.softmax(self.l4(x))\n",
        "        x = self.output(x)\n",
        "        return x\n",
        "\n",
        "class ThirdModel(nn.Module):\n",
        "    # Definindo quantidade de camadas (3) e quantidade de neurônios\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.l1 = nn.Linear(in_features = 28, out_features = 35)\n",
        "        self.l2 = nn.Linear(in_features = 35, out_features = 28)\n",
        "        self.output = nn.Linear(in_features = 28, out_features = 12)\n",
        "\n",
        "    # Utilizando Tanh para a função de ativação\n",
        "    def forward(self, x):\n",
        "        x = F.tanh(self.l1(x))\n",
        "        x = F.tanh(self.l2(x))\n",
        "        x = self.output(x)\n",
        "        return x"
      ],
      "id": "e313ad2f",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "820657e8",
        "outputId": "b251818d-0737-4c94-d2f2-18d032c1abc4"
      },
      "source": [
        "# Inicializando o primeiro modelo\n",
        "first_model = FirstModel()\n",
        "first_model"
      ],
      "id": "820657e8",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FirstModel(\n",
              "  (l1): Linear(in_features=28, out_features=56, bias=True)\n",
              "  (l2): Linear(in_features=56, out_features=84, bias=True)\n",
              "  (l3): Linear(in_features=84, out_features=112, bias=True)\n",
              "  (l4): Linear(in_features=112, out_features=84, bias=True)\n",
              "  (l5): Linear(in_features=84, out_features=56, bias=True)\n",
              "  (l6): Linear(in_features=56, out_features=28, bias=True)\n",
              "  (output): Linear(in_features=28, out_features=12, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f83a22ec",
        "outputId": "07e67d46-1f18-4f05-862a-21d9812ff173"
      },
      "source": [
        "# Inicializando o segundo modelo\n",
        "second_model = SecondModel()\n",
        "second_model"
      ],
      "id": "f83a22ec",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SecondModel(\n",
              "  (l1): Linear(in_features=28, out_features=42, bias=True)\n",
              "  (l2): Linear(in_features=42, out_features=70, bias=True)\n",
              "  (l3): Linear(in_features=70, out_features=42, bias=True)\n",
              "  (l4): Linear(in_features=42, out_features=28, bias=True)\n",
              "  (output): Linear(in_features=28, out_features=12, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7343a90",
        "outputId": "9fa80898-fbd2-4a41-e850-341e8078b6a0"
      },
      "source": [
        "# Inicializando o terceiro modelo\n",
        "third_model = ThirdModel()\n",
        "third_model"
      ],
      "id": "c7343a90",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ThirdModel(\n",
              "  (l1): Linear(in_features=28, out_features=35, bias=True)\n",
              "  (l2): Linear(in_features=35, out_features=28, bias=True)\n",
              "  (output): Linear(in_features=28, out_features=12, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2cf43ab"
      },
      "source": [
        "# Definindo critério e otimização do primeiro modelo\n",
        "first_criterion = nn.CrossEntropyLoss()\n",
        "first_optimizer = torch.optim.Adam(first_model.parameters(), lr = 0.01)"
      ],
      "id": "e2cf43ab",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5307a8c"
      },
      "source": [
        "# Definindo critério e otimização do segundo modelo\n",
        "second_criterion = nn.CrossEntropyLoss()\n",
        "second_optimizer = torch.optim.Adam(second_model.parameters(), lr = 0.01)"
      ],
      "id": "c5307a8c",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f649e97"
      },
      "source": [
        "# Definindo critério e otimização do terceiro modelo\n",
        "third_criterion = nn.CrossEntropyLoss()\n",
        "third_optimizer = torch.optim.Adam(third_model.parameters(), lr = 0.01)"
      ],
      "id": "8f649e97",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dad08756",
        "outputId": "a0544dcd-34e7-4b73-d6ac-af32b2ec48d3"
      },
      "source": [
        "# Executando os modelos na base de treino\n",
        "def print_current_iteration_data(model, epoch, loss):\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Model: {model} - Epoch: {epoch} - Loss: {loss}')\n",
        "\n",
        "epochs = 100\n",
        "first_model_losses = []\n",
        "second_model_losses = []\n",
        "third_model_losses = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Primeiro modelo\n",
        "    y_hat = first_model.forward(X1_train)\n",
        "    loss = first_criterion(y_hat, y1_train)\n",
        "    first_model_losses.append(loss)\n",
        "\n",
        "    print_current_iteration_data('First model', epoch, loss)\n",
        "\n",
        "    first_optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    first_optimizer.step()\n",
        "\n",
        "    # Segundo modelo\n",
        "    y_hat = second_model.forward(X2_train)\n",
        "    loss = second_criterion(y_hat, y2_train)\n",
        "    second_model_losses.append(loss)\n",
        "\n",
        "    print_current_iteration_data('Second model', epoch, loss)\n",
        "\n",
        "    second_optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    second_optimizer.step()\n",
        "\n",
        "    # Terceiro modelo\n",
        "    y_hat = third_model.forward(X3_train)\n",
        "    loss = third_criterion(y_hat, y3_train)\n",
        "    third_model_losses.append(loss)\n",
        "\n",
        "    print_current_iteration_data('Third model', epoch, loss)\n",
        "\n",
        "    third_optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    third_optimizer.step()"
      ],
      "id": "dad08756",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: First model - Epoch: 0 - Loss: 4738.6943359375\n",
            "Model: Second model - Epoch: 0 - Loss: 2.5248208045959473\n",
            "Model: Third model - Epoch: 0 - Loss: 2.3100221157073975\n",
            "Model: First model - Epoch: 10 - Loss: 1403.642578125\n",
            "Model: Second model - Epoch: 10 - Loss: 2.2659919261932373\n",
            "Model: Third model - Epoch: 10 - Loss: 1.1658735275268555\n",
            "Model: First model - Epoch: 20 - Loss: 83.95203399658203\n",
            "Model: Second model - Epoch: 20 - Loss: 2.039792776107788\n",
            "Model: Third model - Epoch: 20 - Loss: 1.1475228071212769\n",
            "Model: First model - Epoch: 30 - Loss: 169.88507080078125\n",
            "Model: Second model - Epoch: 30 - Loss: 1.8438239097595215\n",
            "Model: Third model - Epoch: 30 - Loss: 1.134674072265625\n",
            "Model: First model - Epoch: 40 - Loss: 5.862580299377441\n",
            "Model: Second model - Epoch: 40 - Loss: 1.6741023063659668\n",
            "Model: Third model - Epoch: 40 - Loss: 1.1346585750579834\n",
            "Model: First model - Epoch: 50 - Loss: 2.2572851181030273\n",
            "Model: Second model - Epoch: 50 - Loss: 1.535702109336853\n",
            "Model: Third model - Epoch: 50 - Loss: 1.133301854133606\n",
            "Model: First model - Epoch: 60 - Loss: 2.182950019836426\n",
            "Model: Second model - Epoch: 60 - Loss: 1.430974006652832\n",
            "Model: Third model - Epoch: 60 - Loss: 1.1331731081008911\n",
            "Model: First model - Epoch: 70 - Loss: 2.1125426292419434\n",
            "Model: Second model - Epoch: 70 - Loss: 1.3554561138153076\n",
            "Model: Third model - Epoch: 70 - Loss: 1.1329033374786377\n",
            "Model: First model - Epoch: 80 - Loss: 2.034538984298706\n",
            "Model: Second model - Epoch: 80 - Loss: 1.3022006750106812\n",
            "Model: Third model - Epoch: 80 - Loss: 1.1327533721923828\n",
            "Model: First model - Epoch: 90 - Loss: 1.9519710540771484\n",
            "Model: Second model - Epoch: 90 - Loss: 1.2648063898086548\n",
            "Model: Third model - Epoch: 90 - Loss: 1.1326788663864136\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fc6b77d"
      },
      "source": [
        "# Executando os modelos na base de teste\n",
        "first_model_preds = []\n",
        "second_model_preds = []\n",
        "third_model_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Primeiro modelo\n",
        "    for item in X1_test:\n",
        "        y_hat = first_model.forward(item)\n",
        "        first_model_preds.append(y_hat.argmax().item())\n",
        "\n",
        "    # Segundo modelo\n",
        "    for item in X2_test:\n",
        "        y_hat = second_model.forward(item)\n",
        "        second_model_preds.append(y_hat.argmax().item())\n",
        "\n",
        "    # Terceiro modelo\n",
        "    for item in X3_test:\n",
        "        y_hat = third_model.forward(item)\n",
        "        third_model_preds.append(y_hat.argmax().item())"
      ],
      "id": "0fc6b77d",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fc74875"
      },
      "source": [
        "# Criando dataframes\n",
        "df_first_model_preds = pd.DataFrame({'Y': y1_test, 'YHat': first_model_preds})\n",
        "df_first_model_preds['Correct'] = [1 if corr == pred else 0 for corr, pred in zip(df_first_model_preds['Y'], df_first_model_preds['YHat'])]\n",
        "\n",
        "df_second_model_preds = pd.DataFrame({'Y': y2_test, 'YHat': second_model_preds})\n",
        "df_second_model_preds['Correct'] = [1 if corr == pred else 0 for corr, pred in zip(df_second_model_preds['Y'], df_second_model_preds['YHat'])]\n",
        "\n",
        "df_third_model_preds = pd.DataFrame({'Y': y3_test, 'YHat': third_model_preds})\n",
        "df_third_model_preds['Correct'] = [1 if corr == pred else 0 for corr, pred in zip(df_third_model_preds['Y'], df_third_model_preds['YHat'])]"
      ],
      "id": "9fc74875",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71d5229a",
        "outputId": "3b46456d-3432-4ec1-983e-d9f33867b936"
      },
      "source": [
        "# Calculando acurácia\n",
        "first_model_accuracy = df_first_model_preds.Correct.sum() / len(df_first_model_preds)\n",
        "second_model_accuracy = df_second_model_preds.Correct.sum() / len(df_second_model_preds)\n",
        "third_model_accuracy = df_third_model_preds.Correct.sum() / len(df_third_model_preds)\n",
        "\n",
        "print(f'Model: First model - Accuracy: {first_model_accuracy}')\n",
        "print(f'Model: Second model - Accuracy: {second_model_accuracy}')\n",
        "print(f'Model: Third model - Accuracy: {third_model_accuracy}')"
      ],
      "id": "71d5229a",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: First model - Accuracy: 0.6641104294478528\n",
            "Model: Second model - Accuracy: 0.6789366053169734\n",
            "Model: Third model - Accuracy: 0.6625766871165644\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d483ae4"
      },
      "source": [
        "# Carregando o dataframe hidden\n",
        "df_hidden = pd.read_csv('hidden.csv', sep = ';', decimal = '.')"
      ],
      "id": "3d483ae4",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d1a2353",
        "outputId": "6d791cb8-401d-438c-867a-9beed82f527b"
      },
      "source": [
        "# Visualizando as informações do dataframe hidden\n",
        "df_hidden.info()"
      ],
      "id": "2d1a2353",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2642 entries, 0 to 2641\n",
            "Data columns (total 30 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   DEPTH_MD            2642 non-null   float64\n",
            " 1   X_LOC               2642 non-null   float64\n",
            " 2   Y_LOC               2642 non-null   float64\n",
            " 3   Z_LOC               2642 non-null   float64\n",
            " 4   CALI                2642 non-null   float64\n",
            " 5   RSHA                2642 non-null   float64\n",
            " 6   RMED                2642 non-null   float64\n",
            " 7   RDEP                2642 non-null   float64\n",
            " 8   RHOB                2642 non-null   float64\n",
            " 9   GR                  2642 non-null   float64\n",
            " 10  NPHI                2642 non-null   float64\n",
            " 11  PEF                 2642 non-null   float64\n",
            " 12  DTC                 2641 non-null   float64\n",
            " 13  SP                  2641 non-null   float64\n",
            " 14  BS                  2641 non-null   float64\n",
            " 15  ROP                 2641 non-null   float64\n",
            " 16  DCAL                2641 non-null   float64\n",
            " 17  DRHO                2641 non-null   float64\n",
            " 18  MUDWEIGHT           2641 non-null   float64\n",
            " 19  RMIC                2641 non-null   float64\n",
            " 20  Carbon_Index        2641 non-null   float64\n",
            " 21  Normalized_RHOB     2641 non-null   float64\n",
            " 22  Normalized_GR       2641 non-null   float64\n",
            " 23  Delta_DTC           2641 non-null   float64\n",
            " 24  Delta_RHOB          2641 non-null   float64\n",
            " 25  Delta_GR            2641 non-null   float64\n",
            " 26  Delta_DEPTH_MD      2641 non-null   float64\n",
            " 27  Delta_Carbon_Index  2641 non-null   float64\n",
            " 28  GROUP_encoded       2641 non-null   float64\n",
            " 29  FORMATION_encoded   2641 non-null   float64\n",
            "dtypes: float64(30)\n",
            "memory usage: 619.3 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0198ae87"
      },
      "source": [
        "# Removendo as colunas GROUP_encoded e FORMATION_encoded do dataframe hidden\n",
        "X = df_hidden.drop(['GROUP_encoded', 'FORMATION_encoded'], axis = 1).values"
      ],
      "id": "0198ae87",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c89c9fe"
      },
      "source": [
        "X = torch.FloatTensor(X)"
      ],
      "id": "7c89c9fe",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1b870a5"
      },
      "source": [
        "# Executando os modelos no dataframe hidden\n",
        "first_model_preds = []\n",
        "second_model_preds = []\n",
        "third_model_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for item in X:\n",
        "        # Primeiro modelo\n",
        "        y_hat = first_model.forward(item)\n",
        "        first_model_preds.append(y_hat.argmax().item())\n",
        "\n",
        "        # Segundo modelo\n",
        "        y_hat = second_model.forward(item)\n",
        "        second_model_preds.append(y_hat.argmax().item())\n",
        "\n",
        "        # Terceiro modelo\n",
        "        y_hat = third_model.forward(item)\n",
        "        third_model_preds.append(y_hat.argmax().item())"
      ],
      "id": "d1b870a5",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45e1858d"
      },
      "source": [
        "# Criando dataframes das predições\n",
        "df_first_model_preds = pd.DataFrame({'lithology': first_model_preds})\n",
        "df_second_model_preds = pd.DataFrame({'lithology': second_model_preds})\n",
        "df_third_model_preds = pd.DataFrame({'lithology': third_model_preds})"
      ],
      "id": "45e1858d",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c2c4a5f"
      },
      "source": [
        "# Convertendo os valores indexados da coluna lithology para FORCE_2020_LITHOFACIES_LITHOLOGY\n",
        "mapping = {\n",
        "    0: 30000,\n",
        "    1: 65030,\n",
        "    2: 65000,\n",
        "    3: 80000,\n",
        "    4: 74000,\n",
        "    5: 70000,\n",
        "    6: 70032,\n",
        "    7: 88000,\n",
        "    8: 86000,\n",
        "    9: 99000,\n",
        "    10: 90000,\n",
        "    11: 93000\n",
        "}\n",
        "df_first_model_preds.lithology = df_first_model_preds.lithology.apply(lambda x: mapping[x])\n",
        "df_second_model_preds.lithology = df_second_model_preds.lithology.apply(lambda x: mapping[x])\n",
        "df_third_model_preds.lithology = df_third_model_preds.lithology.apply(lambda x: mapping[x])"
      ],
      "id": "7c2c4a5f",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2488d6e3"
      },
      "source": [
        "# Exportando os resultados para CSV\n",
        "df_first_model_preds.to_csv('cristopher_resultado_rede_neural_1.csv', index = False)\n",
        "df_second_model_preds.to_csv('cristopher_resultado_rede_neural_2.csv', index = False)\n",
        "df_third_model_preds.to_csv('cristopher_resultado_rede_neural_3.csv', index = False)"
      ],
      "id": "2488d6e3",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "461b60bc"
      },
      "source": [
        ""
      ],
      "id": "461b60bc",
      "execution_count": 29,
      "outputs": []
    }
  ]
}